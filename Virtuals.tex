\documentclass[aps,prl,reprint,amsmath,amssymb]{revtex4-1}

\usepackage{epsfig,color,graphicx}
%\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{soul}
\setcitestyle{super}

% Mathematical symbols
\newcommand*{\imi}{i} % imaginary i
\newcommand*{\E}{\mathrm{e}}
% DIRAC NOTATION
% bra-ket vectors
\newcommand{\ket}[1]{\ensuremath{\vert #1 \rangle}}
\newcommand{\bra}[1]{\ensuremath{\langle #1 \vert}}
\newcommand{\braket}[2]{\ensuremath{\langle #1 \vert #2 \rangle}} % bra-ket inner product
\newcommand{\ketbra}[2]{\ensuremath{\vert #1 \rangle \langle #2 \vert}} % ket-bra outer product
% operators
\newcommand{\op}[1]{\ensuremath{\hat{#1}}} % operator


\makeatletter
\renewcommand\NAT@biblabelnum[1]{{(#1)}}
\makeatother

%text color
%\newcommand{\new}{\color{red}}
%\newcommand{\blue}{\color{blue}}
%\newcommand{\old}{\color{black}}

\begin{filecontents*}{NLMOs-ctrl.bib}
@Control{achemso-ctrl,
  ctrl-article-title = {yes}
}
\end{filecontents*}

\begin{document}
\nocite{achemso-ctrl}

\bibliographystyle{achemso}

\title{
[Efficient] variable-metric localization of occupied and virtual one-electron orbitals
}

\author{Ziling Luo}
\email{ziling.luo@mail.mcgill.ca}
\author{Rustam Z. Khaliullin}
\email{rustam.khaliullin@mcgill.ca}
\affiliation{Department of Chemistry, McGill University, 801 Sherbrooke St. West, Montreal, QC H3A 0B8, Canada}

\date{\today}

\begin{abstract}
Comparison of variable-metric localization algorithms for occupied and virtual orbitals based on Boys-Foster and Pipek-Mezey localization functions for gas-phase and periodic systems.
\end{abstract}


\maketitle

\section{Introduction}
 
Spatially localized orbitals are widely used in electronic structure theory.
Occupied localized orbitals help describe, visualize and classify chemical bonding between atoms thus facilitating our understanding of electronic-structure origins of observed properties of atomistic systems.~\cite{boys1960construction, edmiston1963localized, pipek1989fast, niessen1972density, weinhold2012natural}.
Occupied and virtual localized orbitals are crucial ingredients in all local electronic structure methods including Kohn-Sham density functional theory (DFT)~\cite{goedecker1994efficient, bowler2012methods, zalesny2011linear, pulay1986orbital, saebo2001low, pisani2005local, hampel1996local, forner1997numerical} and wavefunction-based electron correlation methods~\cite{saebo1993local, schutz1999low, hetzer2000low, schutz2001low}.
In these methods, it is the locality of one-electron orbitals that allows to dramatically reduce the computational cost of modeling of large systems.

%Spatially localized orbitals are known as localized molecular orbitals (LMOs) in the field of molecular quantum chemistry and maximally localized Wannier functions (MLWFs) in solid state physics and materials science~\cite{marzari2012maximally}.
%Here, they will be collectively referred to as LMOs whereas the eigenstates of the effective one-electron Hamiltonian will be called canonical molecular orbitals (CMOs) regardless of whether the system is isolated or treated with periodic boundary conditions.

The self-consistent field procedure at the heart of Kohn-Sham DFT and most single-reference electronic structure theories yields spatially delocalized one-electron states. Typically, these states are the eigenstates of the effective one-electron Hamiltonian and are known as canonical molecular orbitals (CMOs) in the case of molecules and Bloch orbitals in the case of periodic systems. Here, they will be collectively referred to as CMOs. 
Traditionally, spatially localized orbitals are constructed by finding the unitary transformation of CMOs that minimizes the spread of individual orbitals. 
The unitary transformation can be applied to the set of occupied orbitals, generating a localized description of chemical bonding, or to the set of virtual orbitals, producing local anti-bonding orbitals. 

Multiple functions have been proposed to measure orbital locality in molecular systems. The most known are Boys-Foster~\cite{boys1960construction}, Edmiston-Ruedenberg~\cite{bytautas2002electron, bytautas2003split, edmiston1963localized}, Pipek-Mezey~\cite{pipek1989fast}, and Von Niessen~\cite{niessen1972density} functions. 
The Boys-Foster localization~\cite{boys1960construction} is perhaps the most popular because of the simplicity of its physical interpretation, low computational complexity and ease of implementation. 
The Pipek-Mezey localization~\cite{pipek1989fast}, which maximizes atomic charges~\cite{mulliken1955electronic, lowdin1950non, lehtola2014pipek} of each orbital, is also widely used because it does not mix LMOs representing $\sigma$ and $\pi$ bonds and thus gives a clear picture of bonding patterns. 
In the last decade, these well-established localization functions have been modified to reduce orbital tails and produce more uniform localization across a set of orbitals~\cite{jansik2011local, hoyvik2012orbital, hoyvik2012trust, hoyvik2013pipek, lehtola2013unitary, lehtola2014pipek}, especially virtual LMOs~\cite{jansik2011local, hoyvik2012orbital}.

For periodic systems, maximally localized Wannier functions (MLWFs)~\cite{marzari2012maximally,marzari1997maximally} represent the solid-state equivalent of Boys-Foster orbitals. 
%RZK: marzari1997maximally: Marzari, N., and D. Vanderbilt, 1997, Phys. Rev. B 56, 12 847.
For large supercells of condensed phase periodic systems, where electronic structure can be described with the $\Gamma$-point sampling of the Brillouin zone, generalized Pipek-Mezey Wannier functions have also been proposed~\cite{jonsson2017theory}. 
In this work, Wannier functions and localized molecular orbitals will be referred to as LMOs regardless of whether the system is isolated or treated with periodic boundary conditions.
 
Since CMOs are orthogonal and a unitary transformation applied to them during a localization procedure preserves the orbital metric, LMOs obtained in this way are orthogonal by construction.
Because of the the imposed orthogonality condition, orthogonal LMOs (OLMOs) exhibit small non-zero values even far away from their localization centers. 
These orthogonalization tails reduce orbital locality making orbital-based local correlation methods less computationally efficient. 
They also complicate the interpretation of chemically relevant electronic-structure information and make its transferability from one system to another more difficult. 
%A recent study has suggested that Pipek-Mezey scheme may produce semilocal orbitals in the case of virtual orbitals~\cite{hoyvik2013pipek} due to the system and basis set dependence property of the localization function. [RZK: There are lots of issues with PM orbitals or with virtual orbitals. Do we really want to single out this problem? We should mention this specific problem only if it is relevant to the work that we do here. Is it related to the orthogonalization tails?] 

To mitigate the undesirable orthogonality effects, metric-preserving unitary transformation has been applied to nonorthogonal orbitals~\cite{hoyvik2017generalising} and, in a more dramatic procedure, the unitary localization transformations have been replaced by with more general variable-metric nonsingular transformations~\cite{anderson1968self, diner1968fully, magnasco1974localized, payne1977hartree, mehler1977self, feng2004An_efficient, cui2010efficient, luo2020direct}. 
%RZK: occupied NLMOs only?
In the latter procedure, the generalization lifts the orthogonality constraint imposed on LMOs in the localization procedure and increases the number of degrees of freedom available to LMOs. 
It has been found that occupied nonorthogonal LMOs~(NLMOs) obtained in a variable-metric procedure are indeed about $10-30\%$ more localized than OLMOs if measured by the value of the Boys-Foster function~\cite{feng2004An_efficient, liu2000nonorthogonal, luo2020direct}. 

In contrast to metric-preserving unitary transformations, the variable-metric localization must be formulated to avoid
linear dependencies of orbitals during the minimization of the localization function~\cite{liu2000nonorthogonal, feng2004An_efficient, cui2010efficient, peng2013effective}. 
One approach to overcome the linear dependence problem, is to fix the centers of NLMOs~\cite{feng2004An_efficient, cui2010efficient} at the positions guessed from the knowledge of bonding patterns in the system~\cite{cui2010efficient} or at the centers of OLMOs~\cite{feng2004An_efficient}. 
Another more recent approach is to augment the localization function with a term that measures the deviation from the orthogonality and penalizes the states that are too close to linear dependence~\cite{luo2020direct}. The latter reformulation of variable-metric localization allows not only to determine optimal positions of the NLMOs' centers in a unconstrained and straightforward minimization procedure but to choose the desired balance between the orthogonality and locality of the orbitals. 

%RZK: Is this problem relevant to our current discussion? Unfortunately, The recent study has surprisingly shown that a pair of $\sigma$ and $\pi$ bonds tend to generated mixed $\tau$ and $\tau'$ orbitals for nonorthogonal LMOs~(NLMOs). NLMO-abbreviation
%RZK- related: The Pipek-Mezey localization function is know for the ability to preserve the separation of $\sigma$ and $\pi$ bonds, but the recent study has demonstrated the $\sigma$-$\pi$ separation cannot be expected for NLMOs~\cite{luo2020direct}.


\textbf{Algorithms.} 

A variety of methods and algorithms have been developed to construct LMOs. 
In the case of OLMOs, the orthogonality is preserved through Jacobi sweeps~\cite{edmiston1963localized, barr1975improved} or by exponential parameterization of unitary transformations~\cite{berghold2000general}. 

Pioneering work by Luenberger [28] and Gabay [29] convert the constrained optimization problem [over unitary matrices] into an unconstrained problem, on an appropriate differentiable manifold.

%[RZZK: combine with previous?] For periodic systems, several efficient optimization algorithms have been proposed to construct Wannier function~\cite{marzari1997maximally, berghold2000general, marzari2012maximally, jonsson2017theory}. 
%
%RZK: What algorithm is used in:
%marzari2012maximally, marzari1997maximally
%jonsson2017theory
%
Jacobi sweeps -- an early localization algorithm cpnsisting of a consecutive mixing of orbitals pairs -- approach to localize orbitals. Because of its simplicity, the Jacobi optimization process is often slow and rarely converges in the case of virtual orbitals~\cite{RZK-citation-is-needed,subotnik?}. 

%RZK: Crazy rotations -- citation needed. What is the essence of the algorithm?

%RZK: What is the main advantage of 

Line methods 
The line search methods have been found to be more efficient than the two-by-two orbital transformation for occupied orbitals, even for the simplest steepest descent approach~\cite{edmiston1965localized}.
Conjugate gradient methods, which are typically outperform the steepest descent algorithm, fail to significantly improve the efficiency of the localization procedure~\cite{ryback1978application}.
Multiple second-order methods have also been suggested to accelerate the localization process of occupied orbitals by using the information from the gradient and Hessian.~\cite{leonard1982quadratically, kari1984parametrization}
Even though the Hessian involved methods are more time consuming compared with first-order methods, they successfully reduce the necessary amount of iterations by 1-2 orders of magnitude~\citet{leonard1982quadratically}.
The quasi-Newton methods such as Broyden-Fletcher-Goldfarb-Shanno~(BFGS) algorithm have also been implemented to localize molecular orbitals.~\cite{kari1984parametrization}

In the case of virtual OLMOs, 
Due to the fact that there are multiple not well separated local minimum of the localization functions in the case of virtual orbitals~\cite{subotnik2005fast} convergence is slow for line search methods even with the .
Moreover, the negative Hessian eigenvalues in the initial iterations of orbital localization prevent correctly predicting new directions, therefore the line search methods may fail in the early stage of the optimization process~\cite{RZK-citation-is-needed}.

More recently, the trust region methods have been demonstrated as an ideal optimization algorithm to localize both occupied and virtual orbitals with various localization functions.~\cite{jansik2011local, hoyvik2012trust, hoyvik2012orbital, hoyvik2013pipek}
However, the comparison between different localization functions has suggested the virtual orbitals obtained by Boy-Foster and Pipek-Mezey schemes are less localized than more advanced and complicated localization schemes.~\cite{hoyvik2013localized} 

Multiple optimization methods have also been implemented for localizing nonorthogonal orbitals.
The trust region methods have successfully applied to metric-preserving nonorthogonal occupied and virtual orbitals.~\cite{hoyvik2017generalising}
The line search methods such as conjugated gradient~\cite{liu2000nonorthogonal}, the Newton method~\cite{feng2004An_efficient} and BFGS method~\cite{cui2010efficient} have been suggested to localize variable-metric nonorthogonal occupied orbitals.

In this work, we designed, tested and compared a variety of line search and trust region algorithms to perform direct unconstrained variable-metric localization of occupied and virtual orbitals. [Currently, there are no reports/methods for variable-metric localization of virtual orbitals (is it true?). Here, we do not only discuss optimization algorithms but also compare, for the first time, virtual NLMOs generated with Boys and PM localization functions.]

[Line search methods depend on the line step size? Discussion ]
[Do we expect more significant reduction in orbital locality for virtual NLMOs than for occupied NLMOs?]

\section{Methodology}

\subsection{Theory}

Conventional tensor notation is used to manipulate nonorthogonal orbitals~\cite{head1998tensor}: covariant quantities are denoted with subscripts, contravariant quantities -- with superscripts. A summation is implied over the same covariant and contravariant orbital indices. Summation is not implied if two indices are both covariant or if indices do not refer to orbitals.

In order to obtain a set of nonorthogonal LMOs, which tend to be more localized than orthogonal LMOs, the orthogonality constraint is replaced with the weaker normalization constraint. Thus, the coefficients in the linear expansion of NLMOs $\ket{j}$ in terms of the initial one-electron states $\ket{i_0}$
%
\begin{equation}
\begin{split}
\ket{j} = \ket{i_0} {A^i}_j 
\end{split}
\end{equation}
%
are not required to form a unitary matrix. The normalization constraint is imposed on NLMOs by expressing the coefficients in terms of independent optimization parameters denoted with lowercase $\mathbf{a}$
%
\begin{equation}
\begin{split}
{A^i}_j = {a^i}_{j} ({a^k}_{j} \sigma^0_{kl}{a^l}_{j})^{-\frac{1}{2}} \equiv {a^i}_{j} N_j ,
\end{split}
\end{equation}
%
where the $\mathbf{a}$-dependent normalization coefficient $N_j$ is defined for brevity. Here and below, and $\sigma_0$ and $\sigma$ denote overlap matrices of the initial orbitals and NLMOs
%
\begin{equation} \label{eq:sigma}
\begin{split}
\sigma_{ji}^0 &= \braket{j_0}{i_0} \\
\sigma_{kl} &= \braket{k}{l} = {A^j}_k \sigma_{ji}^0{A^i}_l
\end{split}
\end{equation}
%
Note that the initial occupied one-electron states are not required to be canonical or orthogonal but need to be normalized and linearly independent. 

Without the orthogonality constraint, a conventional localization function $\Omega_L$ must be augmented by a penalty function $\Omega_P$ that prevents NLMOs from becoming linearly dependent during the optimization~\cite{luo2020direct}
%
\begin{equation} \label{eq:fun-overall}
\begin{split}
\Omega(\mathbf{A}) = \Omega_L(\mathbf{A}) + c_P \Omega_P(\mathbf{A})
\end{split}
\end{equation}
%
where $c_P > 0$ is the penalty strength. Although many penalty functions can be envisioned its has been found that
%
\begin{equation} \label{eq:fun-pen}
\begin{split}
\Omega_P(\mathbf{A}) = - \ln \det \left[ \sigma (\mathbf{A}) \right],
\end{split}
\end{equation}
%
works well with a variety of optimization algorithms. %RZK, perhaps because [the determinant of] the overlap is quadratic function of the expansion coefficients $\mathbf{A}$ and is approximately quadratic with respect to optimization parameters $\mathbf{a}$.
%
Since NLMOs remain normalized in the optimization procedure, the determinant of $\sigma$ lies in the $(0,1]$ interval. It is 1 for orthogonal NLMOs and 0 for linearly dependent NLMOs. Consequently, the penalty function between 0 and $+\infty$ for these two extreme cases, respectively, making linearly dependent state inaccessible in the localization procedure with finite penalty strength $c_P$. 

It is convenient to write the penalty strength $c_P$ as a product of a dimensionless parameter $\alpha$ and the initial value of the localization function 
%
\begin{equation} \label{eq:cp-beta}
\begin{split} 
c_P = \alpha \, \Omega_L(\mathbf{I})
\end{split}
\end{equation}
%
This factorization makes units of the localization and penalty terms consistent. The value of $\alpha$ must be optimized to achieve a desirable compromise between orbital locality and linear independence. A simple strategy to determine $\alpha$ is to set it initially to a sufficiently large value and then gradually decrease it until the determinant of the overlap of NLMOs drops below a desired threshold $\text{D}_{\text{tar}} \in (0,1]$. It has been found~\cite{luo2020direct} that the initial value 
%
\begin{equation} \label{eq:alpha-init}
\begin{split} 
\alpha^{\text{init}}= \left(\ln\frac{\det\sigma(\mathbf{I})}{\text{D}_{\text{tar}}}\right)^{-1}
\end{split}
\end{equation}
%
is sufficiently large to ensure linear independence of NLMOs during the first crucial steps of the localization but, at the same time, is not significantly larger than its optimal value.

The localization functions adopted in this work can be written as
%
\begin{equation} \label{eq:fun-loc}
\begin{split}
\Omega_L(\mathbf{A}) &= - \sum_K \sum_i \omega_K \vert z_{i}^{K} \vert^2, \\
z_{i}^{K} & =  {A^m}_i \bra{m_0} \op{B}^K \ket{n_0} {A^n}_i = {A^m}_i B^{K}_{mn} {A^n}_i
\end{split}
\end{equation}
%
with index $i$ referring to NLMOs and other variables having different meaning depending on the localization method. 

The Berghold~\cite{resta1998quantum, resta1999electron, berghold2000general} localization function $\Omega_L^{\text{B}}$ is equivalent to the Boys-Foster localization scheme~\cite{berghold2000general, resta1999electron} for gas-phase system and describes electronic states within the  $\Gamma$-point approximation for periodic system:
%
\begin{equation} \label{eq:berghold}
\begin{split}
\op{B}^{K} &= \E^{\imi \mathbf{G}_K \cdot \mathbf{\op{r}}}
\end{split}
\end{equation}
%
where $\mathbf{\op{r}}$ is the position operator in three dimensions, $\omega_K$ and $\mathbf{G}_K$ are suitable sets of weights and reciprocal lattice vectors, respectively, labeled by index $K$~\cite{silvestrelli1999maximally, berghold2000general}. 

In the Pipek-Mezey~\cite{pipek1989fast,lehtola2014pipek} localization function $\Omega_L^{\text{PM}}$
%
\begin{equation} \label{eq:pipek}
\begin{split}
%\Omega_L^{\text{PM}}(\mathbf{A}) &= - \sum_{K=1}^{\text{Atoms}} \sum_i \vert z_{i}^{K} \vert^2, \\
%z_{i}^{K} &= {A^m}_i B^{K}_{mn} {A^n}_i, \\
%B^{K}_{mn} &= \frac{1}{2} \sum_{\mu \in K} \bra{m_0}  \left( \ketbra{\chi_{\mu}}{\chi^{\mu}} + \ketbra{\chi^{\mu}}{\chi_{\mu}} \right) \ket{n_0}
\op{B}^{K} &= \frac{1}{2} \sum_{\mu \in K} \left( \ketbra{\chi_{\mu}}{\chi^{\mu}} + \ketbra{\chi^{\mu}}{\chi_{\mu}} \right)
\end{split}
\end{equation}
%
$z_{i}^{K}$ is the contribution of orbital $i$ to the Mulliken charge of atom $K$, $\ket{\chi_\mu}$ and $\ket{\chi^\mu}$ are atom-centered covariant and contravariant basis set functions, atomic weights $\omega_K$ are all set to one and the imaginary part of $z_{i}^{K}$ is zero~\cite{silvestrelli1999maximally, berghold2000general}. The summation over $\mu$ is written explicitly to emphasize that it is restricted to the basis functions centered on atom $K$. 

Efficient optimization of the loss function, requires its gradients and (desirably) second derivatives with respect to the independent parameters $\mathbf{a}$. These can be conveniently written in terms of the gradients and second derivatives with respect to mixing coefficients $\mathbf{A}$.

RZK: all terms must be defined properly. The gradient ${G_i}^j \equiv \frac{\partial \Omega}{\partial {a^i}_j}$ is a sum of the localization ${L_i}^j \equiv \frac{\partial \Omega_L}{\partial {a^i}_j}$ and penalty ${P_i}^j \equiv \frac{\partial \Omega_P}{\partial {a^i}_j}$ components
%
\begin{equation} \label{eq:grad}
\begin{split}
G{_k}^{l} = L{_k}^{l} + c_P P{_k}^{l}.
\end{split}
\end{equation}
%

%
\begin{equation} \label{eq:grad-convert}
\begin{split}
{X_i}^j & = \tilde{X}{_k}^l \frac{\partial {A^k}_l}{\partial {a^i}_j} = \left[ \tilde{X}{_i}^j - ( \sigma_{in}^0 {A^n}_j ) ( {A^m}_j \tilde{X}{_m}^j ) \right] N_j 
\end{split}
\end{equation}
%
\begin{equation} \label{eq:grad-loc}
\begin{split}
\tilde{L}{_k}^l & = - \sum_K {4 \omega_K} \times \\ 
%%%: this was for the log function \tilde{L}{_k}^l & = - \sum_K \frac{4 \omega_K}{\vert z_{l}^{K} \vert^2} \times \\ 
&\times \left[  \operatorname{Re}(B^{K}_{kn}) {A^{n}}_{l} \operatorname{Re}(z_{l}^{K}) + \operatorname{Im}(B^{K}_{kn}) {A^{n}}_{l} \operatorname{Im}(z_{l}^{K}) \right]
\end{split}
\end{equation}
%
\begin{equation} \label{eq:grad-pen}
\begin{split}
\tilde{P}{_k}^l & = -2 \sigma_{km}^0 {A^m}_n \sigma^{nl}
\end{split}
\end{equation}
%
Note that the penalty term ensures that that the overlap matrix remains not only invertible but also well-conditioned. Thus, its inverse $\sigma^{nl}$ can be computed efficiently. 

The hessian ${H_{is}}^{jt} \equiv \frac{\partial \Omega}{\partial {a^i}_j \partial{a^s}_t}$ is also expressed as the sum of the localization Eq.~(\ref{eq:hessian-loc}) and penalty Eq.~(\ref{eq:hessian-pen}) components


%
\begin{equation} \label{eq:hessian-convert}
\begin{split}
{Y_{is}}^{jt} &= \sum_{k,x} \tilde{Y}_{kx}^{jt} \frac{\partial {A^k}_j}{\partial {a^i}_j} \frac{\partial {A^x}_t}{\partial {a^s}_t} + \sum_{k} \tilde{X_k}^j \frac{\partial {A^k}_l}{\partial {a^i}_j \partial{a^s}_t}  \\
&= \left[ \tilde{Y}{_{js}}^{jt} - \sum_{x}\left(\tilde{Y}{_{ix}}^{jt} {A^x}_t \right)\left(\sigma^0 A\right)_{st} - \right.\\
&\left. - \sum_{k}\left(\tilde{Y}{_{ks}}^{jt} {A^k}_j\right)\left(\sigma^0 A\right)_{ij} + \right.\\
&\left. + \sum_{k,x}\left({A^k}_j \tilde{Y}{_{kx}}^{jt} {A^x}_t\right)\left(\sigma^0 A\right)_{ij}\left(\sigma^0 A\right)_{st} \right] \times N_j N_t + \\
&+ \left[ -\tilde{X_i}^t \left(\sigma^0 A \right)_{st} - \tilde{X_s}^t \left(\sigma^0 A \right)_{it} - \sum_{k} \left( \tilde{X_k}^t {A^k}_t \right)\sigma^0_{is}  + \right.\\
&\left. + 3 \sum_{k} \left(\tilde{X_k}^t {A^k}_t \right) \left(\sigma^0 A\right)_{it} \left(\sigma^0 A\right)_{st} \right] \times N_{t}^2
\end{split}
\end{equation}
%


%
\begin{equation} \label{eq:hessian-loc}
\begin{split}
\tilde{M}{_{is}}^{jt} &= - \sum_K {4 \omega_K} \times \\ 
&\times \left[  \operatorname{Re}(B^{K}_{is}) \operatorname{Re}(z_{t}^{K}) + 2 \operatorname{Re}(B^{K}_{in}){A^{n}}_{t} \operatorname{Re}(B^{K}_{sq}){A^{q}}_{t} +  \right. \\
&\left. + \operatorname{Im}(B^{K}_{is}) \operatorname{Im}(z_{t}^{K}) + 2 \operatorname{Im}(B^{K}_{in}){A^{n}}_{t} \operatorname{Im}(B^{K}_{sq}){A^{q}}_{t}  \right] \times \delta_{jt}
\end{split}
\end{equation}
%

%
\begin{equation} \label{eq:hessian-pen}
\begin{split}
\tilde{Q}{_{is}}^{jt} = 2\left(\sigma_{im}^0 {A^m}_n \sigma^{nt}\right)\left(\sigma_{sp}^0 {A^p}_q \sigma^{qj}\right)
\end{split}
\end{equation}
%



\subsection{Multidimensional line Search Methods}

\begin{figure}
\begin{algorithm}[H]
  \caption{Line search minimization of $\Omega$}
  \label{alg:cg}
   \begin{algorithmic}[1]
   	%\Procedure{Minimize$\Omega$}{$c_P, \tau, \mathbf{T}_0$}
	\State Input $\epsilon$ \Comment{Localization convergence threshold}
	\State Input $\text{D}_{\text{tar}}$ \Comment{Minimum allowed NLMO determinant}
   	\State Input $\mathbf{T}_0$ \Comment{Initial basis set coefficients for $\ket{i_0}$}
   	\State Input $\mathbf{S}$ \Comment{Basis set overlap}
   	\State Input $\mathbf{L}^K$ \Comment{Basis set representation of the localization operator} 
   	\State $\mathbf{\sigma}_0 \gets \mathbf{T}_0^{\dagger} \mathbf{ST}_0$ \Comment{Initial orbital overlap} 
   	\State $\mathbf{B}^{K} \gets \mathbf{T}_0^{\dagger} \mathbf{L}^K \mathbf{T}_0$ \Comment{Initial localization matrix, Eq.~(\ref{eq:fun-loc})} 
	\State $\mathbf{a} \gets \mathbf{I}$ \Comment{Initial guess on variational parameters}
	%\State Converged $\gets$ False
	\State StopOuter $\gets$ False \Comment{Flag to exit the outer loop}
	\State $i_{\text{Outer}} \gets 0$ \Comment{Iteration counter}
	\Repeat \Comment{Loop to change the penalty strength}
		\State $i \gets i_{\text{Outer}} + 1$ 
		\State Stop $\gets$ False \Comment{Flag to exit the optimization loop}
		\State $i \gets 0$ \Comment{Iteration counter}
%		\State $\beta \gets 0$ \Comment{Reset conjugation}
		\Repeat \Comment{Fixed-penalty localization loop}
			\State $i \gets i + 1$ 
			\State $\mathbf{A} \gets \mathbf{a} \left[ \text{diagonal}(\mathbf{a}^{\dagger} \mathbf{\sigma}_0 \mathbf{a}) \right]^{-\frac{1}{2}}$ \Comment{Update NLMOs}
			\State $\mathbf{\sigma} \gets \mathbf{A}^{\dagger}\mathbf{\sigma}_0 \mathbf{A}$ \Comment{Update overlap}
			\State $\text{Det} \gets \text{determinant} (\mathbf{\sigma})$ \Comment{Determinant}
			\State $\Omega_{P} \gets - \ln [\text{Det}] $ \Comment{Orthogonalization function}
			\State $\mathbf{P} \gets \text{Eq~(\ref{eq:grad-pen}) and~(\ref{eq:grad-convert})}$ \Comment{Orthogonalization gradient}
			\State $\Omega_{L} \gets \text{Eq~(\ref{eq:fun-loc})}$ \Comment{Localization function}
			\State $\mathbf{L} \gets \text{Eq~(\ref{eq:grad-loc}) and~(\ref{eq:grad-convert})}$ \Comment{Localization gradient}
			\If{$i_{\text{Outer}}=1$ \textbf{and} $i=1$} 
				\State $c_{P} \gets \Omega_{L}(\ln [\text{Det} / \text{D}_{\text{tar}} ])^{-1}$ \Comment{Initial strength}
			\EndIf
			\State $\Omega \gets \Omega_{L} + c_P \Omega_{P} $ 
			\If{$i>1$}
				\State $\mathbf{\Gamma} \gets \mathbf{G}$ \Comment{Save old gradient}
			\EndIf 
			\State $\mathbf{G} \gets \mathbf{L} + c_P \mathbf{P} $ 
			%\State $\text{Error}_\text{CG} \gets \vert\vert \mathbf{G} \vert \vert_{\text{max}}$
			\If{$\vert\vert \mathbf{G} \vert \vert_{\text{max}} < \epsilon$}
				\State Stop $\gets$ True
			\EndIf
			
			\If{\textbf{not} Stop}
				\State $D \gets $ \text{Key difference between line search methods} \Comment{Search direction}
				\State $\alpha \gets \text{argmin}_{\alpha} \Omega(\mathbf{a} + \alpha \mathbf{D})$ \Comment{1D Line search}
				\State $\mathbf{a}\gets \mathbf{a} + \alpha \mathbf{D}$ \Comment{Update variational DOFs}
			\EndIf
		\Until{Stop} 
		\If{$\text{Det} < \text{D}_{\text{tar}}$ \textbf{or} $i_{\text{Outer}} > N_{\text{Outer}}^{\text{Max}}$}
			\State StopOuter $\gets$ True
		\EndIf
		\If{$i_{\text{Outer}}>1$} 
			\State $c_{P} \gets c_P \cdot r$ \Comment{Reduce $c_P$ by factor $r \in (0,1)$}
		\EndIf
	\Until{StopOuter}
	\State $\mathbf{return}$ $\mathbf{T} \gets \mathbf{T}_0 \mathbf{A} $ \Comment{Return NLMOs coefficients}
	%\EndProcedure
   \end{algorithmic}
\end{algorithm}
\caption{\label{fig:cg} Line search algorithm for the optimization of NLMOs.}
\end{figure}

Multidimensional line search approach are the most popular optimization methods, which determine a descent direction along which the objective function will be reduced followed by computing a step size that discover how far to move along that direction.
%
\begin{equation} \label{eq:LS_methods}
\begin{split} 
a_{k+1} = a_{k} + \alpha_{k}D_{k}
\end{split}
\end{equation}
%
where RZK: define your variables, $\alpha$ is a bad choice for the step size because $\alpha$ is already used in the penalty strength.

The descent direction has been suggested by various methods. In this work, we will implement and compare the NLMO optimization between gradient descent, conjugate gradient~(CG),  \emph{quasi}-Newton methods such as limited-memory Broyden–Fletcher–Goldfarb–Shanno~(BFGS) ,and hybrid CG-BFGS. The general descent direction of gradient methods takes the following form:
%
\begin{equation} \label{eq:descent_dir}
\begin{split}
D_{k+1} = -G_{k+1} + \beta_k D_{k}
\end{split}
\end{equation}
%
where  $\beta_0=0$, and for $k \geq 1$
\begin{equation} \label{eq:beta}
\begin{split}
\beta_{k}^\text{GD} &= 0, \\
\beta_{k}^\text{CGFR} &= \frac{\lVert{G_{k+1}}\rVert^2}{\lVert{G_{k}}\rVert^2} \\
\beta_{k}^\text{CGDY} &=  \frac{\lVert{G_{k+1}}\rVert^2}{D_{k}^{T}(G_{k+1}-G_{k})} \\
\end{split}
\end{equation}
%
CGFR and CGDY correspond to the Fletcher-Reeves~\citep{fletcher1964function}  and Dai-Yuan~\cite{dai1999nonlinear} choices for the conjugate gradient update factor




In Newton and \emph{quasi}-Newton  methods, the search direction $D_{k}$ is given by the solution of the analogue of the Newton equation:
%
\begin{equation} \label{eq:newton_dir}
\begin{split}
D_{k} = -H_{k}^{-1}G_{k}
\end{split}
\end{equation}
%
By applying the approximate Hessian matrix~$B_{k}$ (or more frequently the inverse of approximate Hessian matrix~$B_{k}^{-1}$),  the \emph{quasi}-Newton methods are expected to converge faster compared with gradient methods without computing the exact Hessian matrix. The BFGS method is one of the most popular members among  \emph{quasi}-Newton methods. The inverse of the approximate Hessian matrix is defined by 
%
\begin{equation} \label{eq:bfgs_inverH}
\begin{split}
B_{k+1}^{-1}  &= (I - \rho_{k}s_{k}y_{k}^{T})B_{k}^{-1}(I - \rho_{k}y_{k}s_{k}^{T}) + \rho_{k}s_{k}s_{k}^{T} \\
\rho_{k} &= \frac{1}{y_{k}^{T}s_{k}}
\end{split}
\end{equation}
%
where $y_{k} = G_{k+1} - G_{k}, s_{k} = a_{k+1} - a_{k}$.
The limited-memory BFGS~(L-BFGS) method uses the curvature information from only the most recent iterations to construct the inverse of Hessian approximation by applying a recursive procedure, which is particular well suited for solving large problems whose Hessian matrix cannot be computed at a reasonable cost or are not sparse.

The hybrid CG-BFGS methods combines the best properties of both BFGS and CG methods and are expected to significantly improve the total number of iterations and computing time. 
%
\begin{equation} \label{eq:hybrid_dir}
\begin{split}
D_{k+1} &= -B_{k+1}^{-1}G_{k+1} - l_{k+1}G_{k+1} + \beta_{k+1}^{LSCD}D_{k}, \\
l_{k+1} &= 1 + \beta_{k+1}^\text{LSCD}\frac{G_{k+1}^{T}D_{k}}{\lVert G_{k+1}\rVert^{2}}
\end{split}
\end{equation}
%
where $\beta_{k}^\text{LSCD}$ is defined as 
%
\begin{equation} \label{eq:beta_LSCD}
\begin{split}
\beta_{k+1}^{LS} &= \frac{y_{k}^{T}G_{k+1}}{-G_{k}^{T}D_{k}}, \beta_{k+1}^{CD} = \frac{\lVert G_{k+1}\rVert^2}{-G_{k}^{T}D_{k}}, \\
\beta_{k+1}^{LSCD} &= \max\Big\{0, \min\Big\{\beta_{k+1}^{LS}, \beta_{k+1}^{CD}\Big\}\Big\}
\end{split}
\end{equation}
%

\subsection{Trust Region Methods}

\begin{figure}
\begin{algorithm}[H]
  \caption{Trust region minimization of $\Omega$}
  \label{alg:tr}
   \begin{algorithmic}[1]
   	%\Procedure{Minimize$\Omega$}{$c_P, \tau, \mathbf{T}_0$}
	\State Input $\epsilon_{\text{TR}}$ \Comment{Localization convergence threshold}
	\State Input $\hat{\Delta}$ \Comment{The overall bound on the step lengths}
	\State Input $\Delta_{0}$ \Comment{Initial trust-region radius}
	%\State Input $N_{\text{CG}}$, $N_{\text{Outer}}$ \Comment{Max CG, outer iterations}
	\State Input $\text{D}_{\text{tar}}$ \Comment{Minimum allowed NLMO determinant}
   	\State Input $\mathbf{T}_0$ \Comment{Initial basis set coefficients for $\ket{i_0}$}
   	\State Input $\mathbf{S}$ \Comment{Basis set overlap}
   	\State Input $\mathbf{L}^K$ \Comment{Basis set representation of the localization operator} 
   	\State $\mathbf{\sigma}_0 \gets \mathbf{T}_0^{\dagger} \mathbf{ST}_0$ \Comment{Initial orbital overlap} 
   	\State $\mathbf{B}^{K} \gets \mathbf{T}_0^{\dagger} \mathbf{L}^K \mathbf{T}_0$ \Comment{Initial localization matrix, Eq.~(\ref{eq:fun-loc})} 
	\State $\mathbf{a} \gets \mathbf{I}$ \Comment{Initial guess on variational parameters}
	%\State Converged $\gets$ False
	\State StopOuter $\gets$ False \Comment{Flag to exit the outer loop}
	\State $i_{\text{Outer}} \gets 0$ \Comment{Iteration counter}
	\Repeat \Comment{Loop to change the penalty strength}
		\State $i_{\text{Outer}} \gets i_{\text{Outer}} + 1$ 
		\State StopTR $\gets$ False \Comment{Flag to exit the TR loop}
		\State $i_{\text{TR}} \gets 0$ \Comment{Iteration counter}
%		\State $\beta \gets 0$ \Comment{Reset conjugation}
		\Repeat \Comment{Fixed-penalty localization loop}
			\State $i_{\text{TR}} \gets i_{\text{TR}} + 1$ 
			\State $\mathbf{A} \gets \mathbf{a} \left[ \text{diagonal}(\mathbf{a}^{\dagger} \mathbf{\sigma}_0 \mathbf{a}) \right]^{-\frac{1}{2}}$ \Comment{Update NLMOs}
			\State $\mathbf{\sigma} \gets \mathbf{A}^{\dagger}\mathbf{\sigma}_0 \mathbf{A}$ \Comment{Update overlap}
			\State $\text{Det} \gets \text{determinant} (\mathbf{\sigma})$ \Comment{Determinant}
			\State $\Omega_{P} \gets - \ln [\text{Det}] $ \Comment{Orthogonalization function}
			\State $\mathbf{P} \gets \text{Eq~(\ref{eq:grad-pen}) and~(\ref{eq:grad-convert})}$ \Comment{Orthogonalization gradient}
			\State $\Omega_{L} \gets \text{Eq~(\ref{eq:fun-loc})}$ \Comment{Localization function}
			\State $\mathbf{L} \gets \text{Eq~(\ref{eq:grad-loc}) and~(\ref{eq:grad-convert})}$ \Comment{Localization gradient}
			\If{$i_{\text{Outer}}=1$ \textbf{and} $i_{\text{TR}}=1$} 
				%\State $c_{P} \gets \text{Tr}(\mathbf{L}^{\dagger} \mathbf{P})/\text{Tr}(\mathbf{P}^{\dagger}\mathbf{P})$
				\State $c_{P} \gets \Omega_{L}(\ln [\text{Det} / \text{D}_{\text{tar}} ])^{-1}$ \Comment{Initial strength}
			\EndIf
			\State $\Omega \gets \Omega_{L} + c_P \Omega_{P} $ 
			\If{$i_{\text{TR}}>1$}
				\State $\mathbf{\Gamma} \gets \mathbf{G}$ \Comment{Save old gradient}
			\EndIf 
			\State $\mathbf{G} \gets \mathbf{L} + c_P \mathbf{P} $ 
			%\State $\text{Error}_\text{CG} \gets \vert\vert \mathbf{G} \vert \vert_{\text{max}}$
			\If{$\vert\vert \mathbf{G} \vert \vert_{\text{max}} < \epsilon_{\text{TR}}$}
				\State StopTR $\gets$ True
			\EndIf
%			\If{$i_{\text{CG}}=1$ \textbf{And} $i_{\text{Outer}}=1$}
%				\State StopCG $\gets$ False \Comment{Do first iteration}
%			\EndIf
			\If{\textbf{not} StopTR}
%				\If{$i_{\text{CG}} = 1$}
%					\State $\mathbf{P}^{R_c} \gets \text{Eq.\ref{eq:prec}}(\mathbf{F},\mathbf{M}^{R_c},\mathbf{K}^{R_c}) $\Comment{Precon.}
%				\Else
%					\State $\mathbf{O}_{R_c} \gets \mathbf{D}_{R_c}$ \Comment{Save old direction}
%				\EndIf
                 \State BorderReached $\gets$ False \Comment{Flag to touch the inner border}
                 \State StopInner $\gets$ False \Comment{Flag to exit the TR Inner loop}
                 \Repeat \Comment{TR subproblem loop}
                    \State Curvature $\gets$  $\mathbf{G}^{T}\mathbf{H}\mathbf{G}$
                    \If{Curvature $<$ 0}
                       \State $\tau$ \Comment{Step size to reach the TR border}
                       \State StopInner $\gets$ True
                       \State BorderReached $\gets$ True
                       \State  $m(0)-m(\mathbf{D})$ $\gets$  $\mathbf{G}^{T}\mathbf{D}+\frac{1}{2}\mathbf{D}^{T}\mathbf{H}\mathbf{D}$
                       \State \textbf{break}
                    \Else
                       \State $\mathbf{D}$ \Comment{Compute Step}
                       \State  $m(0)-m(D)$ $\gets$  $\mathbf{G}^{T}\mathbf{D}+\frac{1}{2}\mathbf{D}^{T}\mathbf{H}\mathbf{D}$
                    \EndIf
                 \Until{StopInner} 
                 \State $\rho$ $\gets$ $(\Omega(\mathbf{a}+\mathbf{D})-\Omega(\mathbf{a})) / (m(0)-m(\mathbf{D}))$
                 \If{$\rho < \frac{1}{4}$}
                    \State $\Delta \gets \frac{1}{4}\Delta$
                 \Else
                 \algstore{bkbreak}
   \end{algorithmic}
\end{algorithm}
\end{figure}

\begin{figure}
\addtocounter{algorithm}{-1}
\begin{algorithm}[H]
\caption{Trust region minimization of $\Omega$}
   \begin{algorithmic}[1]
   \algrestore{bkbreak}
                    \If{$\rho > \frac{3}{4}$ \textbf{and} BorderReached}
                       \State $\Delta \gets \min{(2\Delta, \hat{\Delta})}$
                     \Else
                        \State $\Delta \gets \Delta$ \Comment{Remain the same}
                     \EndIf
                 \EndIf
                 \If{$\rho > \eta$}
                    \State $\mathbf{a}\gets \mathbf{a} + \alpha \mathbf{D}$ \Comment{Update variational DOFs}
                  \Else
                     \State $\mathbf{a}\gets  \mathbf{a}$ \Comment{Remain the same}
                 \EndIf
			\EndIf
		\Until{StopCG} 
		\If{$\text{Det} < \text{D}_{\text{tar}}$ \textbf{or} $i_{\text{Outer}} > N_{\text{Outer}}^{\text{Max}}$}
			\State StopOuter $\gets$ True
		\EndIf
		\If{$i_{\text{Outer}}>1$} 
			\State $c_{P} \gets c_P \cdot r$ \Comment{Reduce $c_P$ by factor $r \in (0,1)$}
		\EndIf
	\Until{StopOuter}
	\State $\mathbf{return}$ $\mathbf{T} \gets \mathbf{T}_0 \mathbf{A} $ \Comment{Return NLMOs coefficients}
	%\EndProcedure
   \end{algorithmic}
\end{algorithm}
\caption{\label{fig:tr} Trust region algorithm for the optimization of NLMOs.}
\end{figure}
The trust region methods adopt a different approach to update the step direction and the step size, in which it only takes steps within a trust region around the current iteration. The trust region subproblem  is defined as a second order Taylor series:
%
\begin{equation} \label{eq:tr_subproblem}
\begin{split}
\min m_{k}(D) = f_{k} + G_{k}^T D + \frac{1}{2}D^T B_{k}D    \quad s.t. \lvert D \rvert \leq \Delta_{k}
\end{split}
\end{equation}
%




\section{Results and discussion}

\subsection{Computational details}

RZK: this needs to be adapted from our previous work. 

To test the localization procedure, we constructed NLMOs for several systems ranging from a simple water molecule to complex molecules with non-trivial bonding patterns and to large periodic systems. 
For all systems, the initial CMOs were obtained using the conventional diagonalization-based SCF procedure implemented in the electronic structure module of CP2K. 
The Becke-Lee-Yang-Parr generalized gradient approximation~\cite{becke1988density, lee1988development} was used as the exchange-correlation functional.
Goedecker-Teter-Hutter pseudopotentials~\cite{goedecker1996separable} were used together with a triple-$\zeta$ atom-centered Gaussian basis set with two sets of polarization functions for all atoms. 
The energy cutoff was set at 600 Ry to define the auxiliary plane-wave basis set in the construction of the effective Hamiltonian. 
The integration over the Brillouin zone was performed using the $\Gamma$-point approximation.
%RZK: The initial virtual orbitals are randomly generated followed by projecting out the occupied subspace and orthogonalization.

\subsection{Locality of NLMOs}
 
\begin{table*}[htbp]
\caption{The relative reduction in the localization function and the final determinant of the occupied and virtual NLMO overlap.}
\label{tab:loc}
\centering
\begin{tabular}{l c c c c}
\hline\hline
Molecules & $\Delta_{\text{NLMOs/OLMOs}}^{\text{occ}}$ & $\det(\sigma)^{\text{occ}} $ & $\Delta_{\text{NLMOs/OLMOs}}^{\text{vir}}$ & $\det(\sigma)^{\text{vir}}$ \\
\hline
H$_2$O & 18 & 0.100 & 33 & 0.016 \\ 
CO$_2$ & 30 & 0.025 & 32 & 0.002\\
Borazine (B$_3$N$_3$H$_6$) & 20 & 0.026 & 20 & 0.006 \\
Carborane (C$_2$B$_{10}$H$_{12}$) & 17 & 0.085 & 18 & 0.001 \\ 
1-Butyne (C$_4$H$_6$) & 19 & 0.063 & 25 & 0.001 \\
Benzene (C$_6$H$_6$) & 28 & 0.041 & 19 & 0.006 \\ 
Heptane (C$_7$H$_{16}$) & 12 & 0.122 & & \\ 
C60 & 14 & 0.130 & 6.2 & 0.006 \\
Graphene & 21 & 0.025 & 10 & 0.0001 \\
\hline
Average & 20 & 0.069 & & \\
\hline
\hline
\end{tabular}
\label{table:nonlin}
\end{table*}


\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{occupied_iter.pdf}
\caption{Total steps of each $\alpha$ iteration for occupied carborane, borophene, decacyclene and graphene systems}
\label{fig:occ_iter}
\end{figure*}


\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{occupied_grad.pdf}
\caption{Performance of search direction schemes in the occupied Berghold localization of the MOs}
\label{fig:occ_grad}
\end{figure*}


\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{occupied_walltime.pdf}
\caption{Walltime comparison of the most time consuming $\alpha$ iteration in the occupied Berghold localization}
\label{fig:occ_walltime}
\end{figure*}


\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{virtual_iter.pdf}
\caption{Total steps of each $\alpha$ iteration for virtual carborane, borophene, decacyclene and graphene systems}
\label{fig:vir_iter}
\end{figure*}

\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{virtual_grad.pdf}
\caption{Performance of search direction schemes in the virtual Berghold localization of the MOs}
\label{fig:vir_grad}
\end{figure*}


\begin{figure*}[htb]
\centering
\includegraphics[width=\textwidth]{virtual_walltime.pdf}
\caption{Walltime comparison of the most time consuming $\alpha$ iteration in the virtual Berghold localization}
\label{fig:vir_walltime}
\end{figure*}


\section{Conclusions}

Questions:
1. Should we include newton method and Trust-region Dogleg?
2. Print out virtual orbitals


\section{Acknowledgments} 


%\bibliographystyle{abbrv}
\bibliography{Virtuals,Virtuals-ctrl}

\end{document}

